{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "1. Define Classes & Functions <br>\n",
    "    a. Get list of SEC docs for CIK<br>\n",
    "    b. Extract text, date, item numbers from each link<br>\n",
    "    c. Get price given ticker, data from AlphaVantage<br>\n",
    "    d. Get movement given ticker, date<br>\n",
    "    e. Get index movement<br>\n",
    "    f. Check if date is a weekday, and if necessary, adjust to Friday before<br>\n",
    "    g. Calculate dates for month before, quarter before, year before for historical movement calculations\n",
    "2. GET S&P 500 company info<br>\n",
    "3. Get list of 8K doc links <br>\n",
    "4. Download 8Ks & Stock Movements<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import unicodedata\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import math\n",
    "from config import Config\n",
    "import dateutil.relativedelta\n",
    "import pandas_market_calendars as mcal\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Define Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import unicodedata\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "class SEC_Extractor:\n",
    "    def get_doc_links(cik,ticker):\n",
    "        try:\n",
    "            base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "            inputted_cik = cik\n",
    "            payload = {\n",
    "                \"action\" : \"getcompany\",\n",
    "                \"CIK\" : inputted_cik,\n",
    "                \"type\" : \"8-K\",\n",
    "                \"output\":\"xml\",\n",
    "                \"dateb\" : \"20180401\",\n",
    "            }\n",
    "            sec_response = requests.get(url=base_url,params=payload)\n",
    "            soup = BeautifulSoup(sec_response.text,'lxml')\n",
    "            url_list = soup.findAll('filinghref')\n",
    "            html_list = []\n",
    "            # Get html version of links\n",
    "            for link in url_list:\n",
    "                link = link.string\n",
    "                if link.split(\".\")[len(link.split(\".\"))-1] == 'htm':\n",
    "                    txtlink = link + \"l\"\n",
    "                    html_list.append(txtlink)\n",
    "\n",
    "            doc_list = []\n",
    "            doc_name_list = []\n",
    "            # Get links for txt versions of files\n",
    "            for k in range(len(html_list)):\n",
    "                txt_doc = html_list[k].replace(\"-index.html\",\".txt\")\n",
    "                doc_name = txt_doc.split(\"/\")[-1]\n",
    "                doc_list.append(txt_doc)\n",
    "                doc_name_list.append(doc_name)\n",
    "                # Create dataframe of CIK, doc name, and txt link\n",
    "            df = pd.DataFrame(\n",
    "                {\n",
    "                \"cik\" : [cik]*len(html_list),\n",
    "                \"ticker\" : [ticker]*len(html_list),\n",
    "                \"txt_link\" : doc_list,\n",
    "                \"doc_name\": doc_name_list\n",
    "                }\n",
    "            )\n",
    "        except requests.exceptions.ConnectionError:\n",
    "                sleep(.1)\n",
    "        return df\n",
    "\n",
    "    # Extracts text and submission datetime from document link\n",
    "    def extract_text(link):\n",
    "        try:\n",
    "            r = requests.get(link)\n",
    "            #Parse 8-K document\n",
    "            filing = BeautifulSoup(r.content,\"html5lib\",from_encoding=\"ascii\")\n",
    "            #Extract datetime\n",
    "            try:\n",
    "                submission_dt = filing.find(\"acceptance-datetime\").string[:14]\n",
    "            except AttributeError:\n",
    "                    # Flag docs with missing data as May 1 2018 10AM\n",
    "                submission_dt = \"20180501100000\"\n",
    "            \n",
    "            submission_dt = datetime.datetime.strptime(submission_dt,\"%Y%m%d%H%M%S\")\n",
    "            #Extract HTML sections\n",
    "            for section in filing.findAll(\"html\"):\n",
    "                try:\n",
    "                    #Remove tables\n",
    "                    for table in section(\"table\"):\n",
    "                        table.decompose()\n",
    "                    #Convert to unicode\n",
    "                    section = unicodedata.normalize(\"NFKD\",section.text)\n",
    "                    section = section.replace(\"\\t\",\" \").replace(\"\\n\",\" \").replace(\"/s\",\" \").replace(\"\\'\",\"'\")            \n",
    "                except AttributeError:\n",
    "                    section = str(section.encode('utf-8'))\n",
    "            filing = \"\".join((section))\n",
    "        except requests.exceptions.ConnectionError:\n",
    "                sleep(10)\n",
    "        sleep(.1)\n",
    "\n",
    "        return filing, submission_dt\n",
    "\n",
    "    def extract_item_no(document):\n",
    "        pattern = re.compile(\"Item+ +\\d+[\\:,\\.]+\\d+\\d\")\n",
    "        item_list = re.findall(pattern,document)\n",
    "        return item_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns Dataframe of document links for a given CIK\n",
    "idx = pd.Index\n",
    "class FinDataExtractor:\n",
    "    def __init__(self):\n",
    "        # S&P 500 index data downloaded from Yahoo Finance GSPC\n",
    "        self.gspc_df = pd.read_csv(\"Data/Indexes/gspc.csv\",parse_dates=['Date'],index_col=\"Date\")\n",
    "        # Get VIX index data downloaded from Yahoo Finance\n",
    "        self.vix_df = pd.read_csv(\"Data/Indexes/vix.csv\",parse_dates=['Date'],index_col=\"Date\")\n",
    "        nyse = mcal.get_calendar('NYSE')\n",
    "        self.nyse_holidays = nyse.holidays().holidays\n",
    "        self.all_tickers_data = pd.read_pickle(\"Pickles/all_tickers_data.pkl\")\n",
    "        \n",
    "#Takes datetime object and ticker string, returns price (opening or closing)\n",
    "    def get_historical_movements(self,row,period):\n",
    "        ticker,release_date = row[0],row[1]\n",
    "\n",
    "       #1 Week\n",
    "        if period == \"week\":\n",
    "            e_start = release_date + datetime.timedelta(weeks=-1)\n",
    "            b_start = e_start\n",
    "\n",
    "            e_end = release_date + dateutil.relativedelta.relativedelta(days=-1)\n",
    "            b_end = e_end\n",
    "\n",
    "         #1 Month    \n",
    "        elif period == \"month\":\n",
    "            e_start = release_date + dateutil.relativedelta.relativedelta(months=-1)\n",
    "            b_start = e_start + dateutil.relativedelta.relativedelta(days=-5)\n",
    "\n",
    "            e_end = release_date + dateutil.relativedelta.relativedelta(days=-1)\n",
    "            b_end = release_date + dateutil.relativedelta.relativedelta(days=-6)\n",
    "\n",
    "        #1 Quarter\n",
    "        elif period == \"quarter\":\n",
    "            e_start = release_date + dateutil.relativedelta.relativedelta(months=-3)\n",
    "            b_start = e_start + dateutil.relativedelta.relativedelta(days=-10)\n",
    "\n",
    "            e_end = release_date + dateutil.relativedelta.relativedelta(days=-1)\n",
    "            b_end = release_date + dateutil.relativedelta.relativedelta(days=-11)\n",
    "\n",
    "        #1 Year\n",
    "        elif period == \"year\":\n",
    "            e_start = release_date + dateutil.relativedelta.relativedelta(years=-1)\n",
    "            b_start = e_start + dateutil.relativedelta.relativedelta(days=-20)\n",
    "\n",
    "            e_end = release_date + dateutil.relativedelta.relativedelta(days=-1)\n",
    "            b_end = release_date + dateutil.relativedelta.relativedelta(days=-21)\n",
    "        else:\n",
    "            raise KeyError\n",
    "\n",
    "        e_start = self.weekday_check(e_start)\n",
    "        b_start = self.weekday_check(b_start)\n",
    "        e_end = self.weekday_check(e_end)\n",
    "        b_end = self.weekday_check(b_end)\n",
    "\n",
    "        start_price = self.get_av_data(ticker=ticker,start_date = b_start, end_date = e_start)\n",
    "        end_price = self.get_av_data(ticker=ticker,start_date = b_end, end_date = e_end)\n",
    "        stock_change = self.calculate_pct_change(end_price,start_price)\n",
    "\n",
    "        start_index = self.get_index_price(start_date = b_start, end_date = e_start)\n",
    "        end_index = self.get_index_price(start_date = e_start, end_date = e_end)\n",
    "        index_change =  self.calculate_pct_change(end_index,start_index)\n",
    "\n",
    "        normalized = stock_change - index_change\n",
    "        return normalized\n",
    "\n",
    "    def get_av_data(self,ticker,start_date,end_date,market_open=False):\n",
    "        start_date = start_date.date()\n",
    "        end_date = end_date.date()\n",
    "\n",
    "        try:\n",
    "            if market_open == False:\n",
    "                price = self.all_tickers_data.xs(ticker,0).loc[end_date:start_date,\"adjusted_close\"].mean()\n",
    "            else:\n",
    "                price = self.all_tickers_data.xs(ticker,0).loc[end_date:start_date,\"open\"].mean()\n",
    "        except (KeyError,IndexError):\n",
    "            price = np.nan\n",
    "        return price\n",
    "\n",
    "    # Takes ticker, 8K release date, checks time of release and then calculate before and after price change\n",
    "    def get_change(self,row):\n",
    "        release_date = row['release_date']\n",
    "        ticker = row['ticker']\n",
    "        market_close = release_date.replace(hour=16,minute=0,second=0)\n",
    "        market_open = release_date.replace(hour=9,minute=30,second=0)\n",
    "\n",
    "    # If report is released after market hours, take change of start date close and release date open\n",
    "        if release_date > market_close:\n",
    "            start_date = release_date\n",
    "            end_date = release_date + datetime.timedelta(days=1)\n",
    "            end_date = self.weekday_check(end_date)\n",
    "\n",
    "            price_before_release = self.get_av_data(ticker,start_date,start_date,market_open=False)\n",
    "            price_after_release = self.get_av_data(ticker,end_date,end_date,market_open=True)\n",
    "\n",
    "            index_before_release = self.get_index_price(start_date,start_date,market_open=False)\n",
    "            index_after_release = self.get_index_price(end_date,end_date,market_open=True)\n",
    "\n",
    "            try:\n",
    "                vix = self.vix_df.loc[self.vix_df.index == np.datetime64(start_date.date()),\"Adj Close\"][0].item()\n",
    "            except IndexError:\n",
    "                vix = np.nan\n",
    "\n",
    "        # If report is released before market hours, take change of start date's close and release date's open\n",
    "        elif release_date < market_open:\n",
    "            start_date = release_date + datetime.timedelta(days=-1)\n",
    "            start_date = self.weekday_check(start_date)\n",
    "            end_date = release_date\n",
    "\n",
    "            price_before_release = self.get_av_data(ticker,start_date,start_date,market_open=False)\n",
    "            price_after_release = self.get_av_data(ticker,end_date,end_date,market_open=True) \n",
    "\n",
    "            index_before_release = self.get_index_price(start_date,start_date,market_open=False)\n",
    "            index_after_release = self.get_index_price(end_date,end_date,market_open=True)\n",
    "            try:\n",
    "                vix = self.vix_df.loc[self.vix_df.index == np.datetime64(start_date.date()),\"Adj Close\"][0].item()\n",
    "            except IndexError:\n",
    "                vix = np.nan\n",
    "        # If report is released during market hours, use market close\n",
    "        else:\n",
    "            start_date = release_date\n",
    "            end_date = release_date\n",
    "            price_before_release = self.get_av_data(ticker,start_date,start_date,market_open=True)\n",
    "            price_after_release = self.get_av_data(ticker,end_date,end_date,market_open=False)\n",
    "\n",
    "            index_before_release = self.get_index_price(start_date,start_date,market_open=True)\n",
    "            index_after_release = self.get_index_price(end_date,end_date,market_open=False)\n",
    "            \n",
    "            try:\n",
    "                vix = self.vix_df.loc[self.vix_df.index == np.datetime64(start_date.date()),\"Open\"][0].item()\n",
    "            except IndexError:\n",
    "                vix = np.nan\n",
    "                \n",
    "        price_pct_change = self.calculate_pct_change(price_after_release,price_before_release)\n",
    "        index_pct_change = self.calculate_pct_change(index_after_release,index_before_release)\n",
    "        normalized_change = price_pct_change - index_pct_change\n",
    "\n",
    "        return normalized_change, vix\n",
    "\n",
    "    def get_index_price(self,start_date,end_date,market_open=False):\n",
    "        try:\n",
    "            if market_open == True:\n",
    "                price = self.gspc_df.loc[(self.gspc_df.index >= np.datetime64(start_date.date())) & \n",
    "                                 (self.gspc_df.index <= np.datetime64(end_date)),\"Open\"].mean()\n",
    "            else:\n",
    "                price = self.gspc_df.loc[(self.gspc_df.index >= np.datetime64(start_date.date())) & \n",
    "                                 (self.gspc_df.index <= np.datetime64(end_date)),\"Adj Close\"].mean()\n",
    "        except IndexError:\n",
    "                price = np.nan\n",
    "        return price\n",
    "\n",
    "    def calculate_pct_change(self,end_value,start_value):\n",
    "        pct_change = (end_value - start_value) / start_value\n",
    "        pct_change = round(pct_change,4) * 100\n",
    "        return pct_change\n",
    "\n",
    "    def weekday_check(self,date):  \n",
    "        while date.isoweekday() > 5 or date.date() in self.nyse_holidays:\n",
    "            date = date + datetime.timedelta(days=-1)\n",
    "        return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get S&P 500 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Security</th>\n",
       "      <th>SEC filings</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date first added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>3M Company</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>St. Paul, Minnesota</td>\n",
       "      <td>1976-08-09</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1964-03-31</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABMD</th>\n",
       "      <td>ABIOMED Inc</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Danvers, Massachusetts</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>815094</td>\n",
       "      <td>1981</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>reports</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Security SEC filings             GICS Sector  \\\n",
       "Symbol                                                            \n",
       "MMM              3M Company     reports             Industrials   \n",
       "ABT     Abbott Laboratories     reports             Health Care   \n",
       "ABBV            AbbVie Inc.     reports             Health Care   \n",
       "ABMD            ABIOMED Inc     reports             Health Care   \n",
       "ACN           Accenture plc     reports  Information Technology   \n",
       "\n",
       "                     GICS Sub-Industry    Headquarters Location  \\\n",
       "Symbol                                                            \n",
       "MMM           Industrial Conglomerates      St. Paul, Minnesota   \n",
       "ABT              Health Care Equipment  North Chicago, Illinois   \n",
       "ABBV                   Pharmaceuticals  North Chicago, Illinois   \n",
       "ABMD             Health Care Equipment   Danvers, Massachusetts   \n",
       "ACN     IT Consulting & Other Services          Dublin, Ireland   \n",
       "\n",
       "       Date first added      CIK      Founded       GICS Sub Industry  \n",
       "Symbol                                                                 \n",
       "MMM          1976-08-09    66740         1902             Industrials  \n",
       "ABT          1964-03-31     1800         1888             Health Care  \n",
       "ABBV         2012-12-31  1551152  2013 (1888)             Health Care  \n",
       "ABMD         2018-05-31   815094         1981             Health Care  \n",
       "ACN          2011-07-06  1467373         1989  Information Technology  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get table of the S&P 500 tickers, CIK, and industry from Wikipedia\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "cik_df = pd.read_html(wiki_url,header=0,index_col=0)[0]\n",
    "cik_df['GICS Sector'] = cik_df['GICS Sector'].astype(\"category\")\n",
    "cik_df['GICS Sub Industry'] = cik_df['GICS Sector'].astype(\"category\")\n",
    "cik_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get List of 8K links from SEC Edgar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sec_ext = SEC_Extractor\n",
    "no_parts = 2\n",
    "part_no = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_list = []\n",
    "company_list = cik_df['CIK'].to_dict()\n",
    "for (ticker,cik) in tqdm(company_list.items()):\n",
    "    df_list.append(sec_ext.get_doc_links(cik,ticker))\n",
    "doc_links_df = pd.concat(df_list,axis=0)\n",
    "doc_links_df = doc_links_df.set_index(\"ticker\").join(cik_df['GICS Sector']).join(cik_df['GICS Sub Industry']).reset_index().rename(columns={\"index\":\"ticker\"})\n",
    "doc_links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_links_df.to_pickle(\"Pickles/doc_links_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Download 8Ks & Stock Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into how many parts?3\n",
      "Which part is this?2\n",
      "Number of rows to process at once (10 to 50 recommended)50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:06,  6.34s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cik</th>\n",
       "      <th>txt_link</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>text</th>\n",
       "      <th>release_date</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6411</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>746515.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/746515...</td>\n",
       "      <td>0000746515-16-000065.txt</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>0000746515-16-000065.txt : 20160505 0000746515...</td>\n",
       "      <td>2016-05-05 13:36:32</td>\n",
       "      <td>[Item 5.07]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>746515.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/746515...</td>\n",
       "      <td>0000746515-16-000062.txt</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>0000746515-16-000062.txt : 20160504 0000746515...</td>\n",
       "      <td>2016-05-04 14:46:26</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>746515.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/746515...</td>\n",
       "      <td>0000746515-16-000059.txt</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>0000746515-16-000059.txt : 20160503 0000746515...</td>\n",
       "      <td>2016-05-03 15:12:20</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>746515.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/746515...</td>\n",
       "      <td>0000746515-16-000055.txt</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>0000746515-16-000055.txt : 20160315 0000746515...</td>\n",
       "      <td>2016-03-15 16:08:58</td>\n",
       "      <td>[Item 7.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>746515.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/746515...</td>\n",
       "      <td>0000746515-16-000050.txt</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>0000746515-16-000050.txt : 20160223 0000746515...</td>\n",
       "      <td>2016-02-23 14:28:24</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker       cik                                           txt_link  \\\n",
       "6411   EXPD  746515.0  https://www.sec.gov/Archives/edgar/data/746515...   \n",
       "6412   EXPD  746515.0  https://www.sec.gov/Archives/edgar/data/746515...   \n",
       "6413   EXPD  746515.0  https://www.sec.gov/Archives/edgar/data/746515...   \n",
       "6414   EXPD  746515.0  https://www.sec.gov/Archives/edgar/data/746515...   \n",
       "6415   EXPD  746515.0  https://www.sec.gov/Archives/edgar/data/746515...   \n",
       "\n",
       "                      doc_name  GICS Sector GICS Sub Industry  \\\n",
       "6411  0000746515-16-000065.txt  Industrials       Industrials   \n",
       "6412  0000746515-16-000062.txt  Industrials       Industrials   \n",
       "6413  0000746515-16-000059.txt  Industrials       Industrials   \n",
       "6414  0000746515-16-000055.txt  Industrials       Industrials   \n",
       "6415  0000746515-16-000050.txt  Industrials       Industrials   \n",
       "\n",
       "                                                   text        release_date  \\\n",
       "6411  0000746515-16-000065.txt : 20160505 0000746515... 2016-05-05 13:36:32   \n",
       "6412  0000746515-16-000062.txt : 20160504 0000746515... 2016-05-04 14:46:26   \n",
       "6413  0000746515-16-000059.txt : 20160503 0000746515... 2016-05-03 15:12:20   \n",
       "6414  0000746515-16-000055.txt : 20160315 0000746515... 2016-03-15 16:08:58   \n",
       "6415  0000746515-16-000050.txt : 20160223 0000746515... 2016-02-23 14:28:24   \n",
       "\n",
       "                                  items  \n",
       "6411                        [Item 5.07]  \n",
       "6412  [Item 2.02, Item 2.02, Item 9.01]  \n",
       "6413  [Item 2.02, Item 2.02, Item 9.01]  \n",
       "6414                        [Item 7.01]  \n",
       "6415  [Item 2.02, Item 2.02, Item 9.01]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while part_no > no_parts:\n",
    "    no_parts = int(input(\"Split data into how many parts?\"))\n",
    "    part_no = int(input(\"Which part is this?\"))\n",
    "    \n",
    "chunksize = int(input(\"Number of rows to process at once (10 to 50 recommended)\"))\n",
    "\n",
    "#Load pickle\n",
    "crawled_df = np.array_split(pd.read_pickle(\"Pickles/doc_links_df.pkl\"),no_parts)[part_no-1][:10]\n",
    "crawled_len = len(crawled_df['txt_link'])\n",
    "chunks = math.ceil(crawled_len/chunksize)\n",
    "\n",
    "df_list = []\n",
    "for i, df in tqdm(enumerate(np.array_split(crawled_df,chunks))):\n",
    "    df['text'], df['release_date'] = zip(*df['txt_link'].apply(sec_ext.extract_text))\n",
    "    df['items'] = df['text'].map(sec_ext.extract_item_no)\n",
    "    if not os.path.isfile(\"Data/texts_example{}.csv.gzip\".format(part_no)): #If no file exists, create one with header\n",
    "        df.to_csv(\"Data/texts_example{}.csv.gzip\".format(part_no),chunksize=chunksize,compression=\"gzip\")\n",
    "    else: # else it exists so append without writing the header\n",
    "        df.to_csv(\"Data/texts_example{}.csv.gzip\".format(part_no),mode=\"a\",header=False,compression=\"gzip\",chunksize=chunksize)       \n",
    "    df_list.append(df)\n",
    "    del df\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        gc.collect()\n",
    "df = pd.concat(df_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_dict = cik_df['CIK'].to_dict()\n",
    "cik_dict = {v: k for k, v in cik_dict.items()}\n",
    "df['ticker'] = df['cik'].map(cik_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df1_gen = pd.read_csv(\"Data/texts1.csv.gzip\",compression=\"gzip\",parse_dates=['release_date'],chunksize=1000,index_col=[0])\n",
    "#df2_gen = pd.read_csv(\"Data/texts2.csv.gzip\",compression=\"gzip\",parse_dates=['release_date'],chunksize=1000)\n",
    "df1 = pd.concat([df for df in df1_gen])\n",
    "#df2 = pd.concat([df for df in df2_gen])\n",
    "#df2 = pd.read_csv(\"Data/texts2.csv\",parse_dates=['release_date'],encoding=\"utf_8\",index_col=[0])\n",
    "gc.collect()\n",
    "df = pd.concat([df1],axis=0)\n",
    "gc.collect()\n",
    "df['items'] = df['items'].map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cik</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>txt_link</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>text</th>\n",
       "      <th>release_date</th>\n",
       "      <th>items</th>\n",
       "      <th>price_change</th>\n",
       "      <th>vix</th>\n",
       "      <th>rm_week</th>\n",
       "      <th>rm_month</th>\n",
       "      <th>rm_qtr</th>\n",
       "      <th>rm_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001564590-18-006570.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001564590-18-006570.txt : 20180322 0001564590...</td>\n",
       "      <td>2018-03-22 16:22:07</td>\n",
       "      <td>[Item 5.07]</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23.34</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-3.07</td>\n",
       "      <td>1.78</td>\n",
       "      <td>26.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001090872-18-000002.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001090872-18-000002.txt : 20180214 0001090872...</td>\n",
       "      <td>2018-02-14 16:27:02</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "      <td>6.97</td>\n",
       "      <td>19.26</td>\n",
       "      <td>1.95</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>-3.62</td>\n",
       "      <td>35.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001564590-18-000605.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001564590-18-000605.txt : 20180118 0001564590...</td>\n",
       "      <td>2018-01-18 16:09:52</td>\n",
       "      <td>[Item 5.02, Item 9.01]</td>\n",
       "      <td>0.24</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>4.93</td>\n",
       "      <td>3.15</td>\n",
       "      <td>38.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001090872-17-000015.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001090872-17-000015.txt : 20171120 0001090872...</td>\n",
       "      <td>2017-11-20 16:09:02</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>10.65</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.31</td>\n",
       "      <td>9.54</td>\n",
       "      <td>39.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001090872-17-000011.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001090872-17-000011.txt : 20170815 0001090872...</td>\n",
       "      <td>2017-08-15 16:12:29</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "      <td>4.50</td>\n",
       "      <td>12.04</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker      cik                  doc_name  \\\n",
       "0      A  1090872  0001564590-18-006570.txt   \n",
       "1      A  1090872  0001090872-18-000002.txt   \n",
       "2      A  1090872  0001564590-18-000605.txt   \n",
       "3      A  1090872  0001090872-17-000015.txt   \n",
       "4      A  1090872  0001090872-17-000011.txt   \n",
       "\n",
       "                                            txt_link  GICS Sector  \\\n",
       "0  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "1  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "2  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "3  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "4  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "\n",
       "  GICS Sub Industry                                               text  \\\n",
       "0       Health Care  0001564590-18-006570.txt : 20180322 0001564590...   \n",
       "1       Health Care  0001090872-18-000002.txt : 20180214 0001090872...   \n",
       "2       Health Care  0001564590-18-000605.txt : 20180118 0001564590...   \n",
       "3       Health Care  0001090872-17-000015.txt : 20171120 0001090872...   \n",
       "4       Health Care  0001090872-17-000011.txt : 20170815 0001090872...   \n",
       "\n",
       "         release_date                              items  price_change    vix  \\\n",
       "0 2018-03-22 16:22:07                        [Item 5.07]          0.05  23.34   \n",
       "1 2018-02-14 16:27:02  [Item 2.02, Item 2.02, Item 9.01]          6.97  19.26   \n",
       "2 2018-01-18 16:09:52             [Item 5.02, Item 9.01]          0.24  12.22   \n",
       "3 2017-11-20 16:09:02  [Item 2.02, Item 2.02, Item 9.01]         -0.14  10.65   \n",
       "4 2017-08-15 16:12:29  [Item 2.02, Item 2.02, Item 9.01]          4.50  12.04   \n",
       "\n",
       "   rm_week  rm_month  rm_qtr  rm_year  \n",
       "0    -0.41     -3.07    1.78    26.37  \n",
       "1     1.95     -5.76   -3.62    35.35  \n",
       "2     1.22      4.93    3.15    38.90  \n",
       "3     2.71      1.31    9.54    39.85  \n",
       "4    -0.21     -3.34    4.39    21.40  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-13-b25d0a909d62>:2: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  df = df.loc[~(df['release_date'] >= pd.datetime(year=2018,month=5,day=1))]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert ticker, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b25d0a909d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"doc_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   4857\u001b[0m                 \u001b[0;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4858\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4859\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4861\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3626\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3627\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3628\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3630\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.9/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert ticker, already exists"
     ]
    }
   ],
   "source": [
    "# Find rows flagged where no date was found\n",
    "df = df.loc[~(df['release_date'] >= pd.datetime(year=2018,month=5,day=1))]\n",
    "df = df.drop_duplicates(subset=\"doc_name\")\n",
    "df.index.names = ['ticker']\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cik</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>txt_link</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>text</th>\n",
       "      <th>release_date</th>\n",
       "      <th>items</th>\n",
       "      <th>price_change</th>\n",
       "      <th>vix</th>\n",
       "      <th>rm_week</th>\n",
       "      <th>rm_month</th>\n",
       "      <th>rm_qtr</th>\n",
       "      <th>rm_year</th>\n",
       "      <th>signal</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ticker</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001564590-18-006570.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001564590-18-006570.txt : 20180322 0001564590...</td>\n",
       "      <td>2018-03-22 16:22:07</td>\n",
       "      <td>[Item 5.07]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001090872-18-000002.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001090872-18-000002.txt : 20180214 0001090872...</td>\n",
       "      <td>2018-02-14 16:27:02</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001564590-18-000605.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001564590-18-000605.txt : 20180118 0001564590...</td>\n",
       "      <td>2018-01-18 16:09:52</td>\n",
       "      <td>[Item 5.02, Item 9.01]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001090872-17-000015.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001090872-17-000015.txt : 20171120 0001090872...</td>\n",
       "      <td>2017-11-20 16:09:02</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001090872-17-000011.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001090872-17-000011.txt : 20170815 0001090872...</td>\n",
       "      <td>2017-08-15 16:12:29</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>down</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ticker      cik                  doc_name  \\\n",
       "ticker                                             \n",
       "0           A  1090872  0001564590-18-006570.txt   \n",
       "1           A  1090872  0001090872-18-000002.txt   \n",
       "2           A  1090872  0001564590-18-000605.txt   \n",
       "3           A  1090872  0001090872-17-000015.txt   \n",
       "4           A  1090872  0001090872-17-000011.txt   \n",
       "\n",
       "                                                 txt_link  GICS Sector  \\\n",
       "ticker                                                                   \n",
       "0       http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "1       http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "2       http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "3       http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "4       http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "\n",
       "       GICS Sub Industry                                               text  \\\n",
       "ticker                                                                        \n",
       "0            Health Care  0001564590-18-006570.txt : 20180322 0001564590...   \n",
       "1            Health Care  0001090872-18-000002.txt : 20180214 0001090872...   \n",
       "2            Health Care  0001564590-18-000605.txt : 20180118 0001564590...   \n",
       "3            Health Care  0001090872-17-000015.txt : 20171120 0001090872...   \n",
       "4            Health Care  0001090872-17-000011.txt : 20170815 0001090872...   \n",
       "\n",
       "              release_date                              items  price_change  \\\n",
       "ticker                                                                        \n",
       "0      2018-03-22 16:22:07                        [Item 5.07]           NaN   \n",
       "1      2018-02-14 16:27:02  [Item 2.02, Item 2.02, Item 9.01]           NaN   \n",
       "2      2018-01-18 16:09:52             [Item 5.02, Item 9.01]           NaN   \n",
       "3      2017-11-20 16:09:02  [Item 2.02, Item 2.02, Item 9.01]           NaN   \n",
       "4      2017-08-15 16:12:29  [Item 2.02, Item 2.02, Item 9.01]           NaN   \n",
       "\n",
       "          vix  rm_week  rm_month  rm_qtr  rm_year signal  \n",
       "ticker                                                    \n",
       "0       23.34      NaN       NaN     NaN      NaN   down  \n",
       "1       19.26      NaN       NaN     NaN      NaN   down  \n",
       "2       12.22      NaN       NaN     NaN      NaN   down  \n",
       "3       10.65      NaN       NaN     NaN      NaN   down  \n",
       "4       12.04      NaN       NaN     NaN      NaN   down  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from FinDataExtractor import FinDataExtractor\n",
    "fin_data = FinDataExtractor()\n",
    "## Load pickle of ticker, date, and doc number\n",
    "\n",
    "df['price_change'],df['vix'] = zip(*df[['ticker','release_date']].apply(fin_data.get_change,axis=1))\n",
    "df['rm_week'] = df[['ticker','release_date']].apply(fin_data.get_historical_movements,period=\"week\",axis=1)\n",
    "df['rm_month'] = df[['ticker','release_date']].apply(fin_data.get_historical_movements,period=\"month\",axis=1)\n",
    "df['rm_qtr'] = df[['ticker','release_date']].apply(fin_data.get_historical_movements,period=\"quarter\",axis=1)\n",
    "df['rm_year'] = df[['ticker','release_date']].apply(fin_data.get_historical_movements,period=\"year\",axis=1)\n",
    "df[\"signal\"] = df['price_change'].map(lambda x: \"stay\" if -1<x<1 else (\"up\" if x>1 else \"down\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 74.51it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = 20\n",
    "for i, df_part in tqdm(enumerate(np.array_split(df,chunks))):\n",
    "    if not os.path.isfile(\"Data/texts_and_fin.csv\"): #If no file exists, create one with header\n",
    "        df_part.to_csv(\"Data/texts_and_fin.csv\")\n",
    "    else: # else it exists so append without writing the header\n",
    "        df_part.to_csv(\"Data/texts_and_fin.csv\",mode=\"a\",header=False,)       \n",
    "    del df_part\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
