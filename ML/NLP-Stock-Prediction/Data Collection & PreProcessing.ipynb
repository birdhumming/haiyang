{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection\n",
    "\n",
    "1. Define Classes & Functions <br>\n",
    "    a. Get list of SEC docs for CIK<br>\n",
    "    b. Extract text, date, item numbers from each link<br>\n",
    "    c. Get price given ticker, data from AlphaVantage<br>\n",
    "    d. Get movement given ticker, date<br>\n",
    "    e. Get index movement<br>\n",
    "    f. Check if date is a weekday, and if necessary, adjust to Friday before<br>\n",
    "    g. Calculate dates for month before, quarter before, year before for historical movement calculations\n",
    "2. GET S&P 500 company info<br>\n",
    "3. Get list of 8K doc links <br>\n",
    "4. Download 8Ks & Stock Movements<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import unicodedata\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import math\n",
    "from config import Config\n",
    "import dateutil.relativedelta\n",
    "import pandas_market_calendars as mcal\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Define Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "import unicodedata\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import sleep\n",
    "import re\n",
    "\n",
    "class SEC_Extractor:\n",
    "    def get_doc_links(cik,ticker):\n",
    "        try:\n",
    "            base_url = \"https://www.sec.gov/cgi-bin/browse-edgar\"\n",
    "            inputted_cik = cik\n",
    "            payload = {\n",
    "                \"action\" : \"getcompany\",\n",
    "                \"CIK\" : inputted_cik,\n",
    "                \"type\" : \"8-K\",\n",
    "                \"output\":\"xml\",\n",
    "                \"dateb\" : \"20180401\",\n",
    "            }\n",
    "            sec_response = requests.get(url=base_url,params=payload)\n",
    "            soup = BeautifulSoup(sec_response.text,'lxml')\n",
    "            url_list = soup.findAll('filinghref')\n",
    "            html_list = []\n",
    "            # Get html version of links\n",
    "            for link in url_list:\n",
    "                link = link.string\n",
    "                if link.split(\".\")[len(link.split(\".\"))-1] == 'htm':\n",
    "                    txtlink = link + \"l\"\n",
    "                    html_list.append(txtlink)\n",
    "\n",
    "            doc_list = []\n",
    "            doc_name_list = []\n",
    "            # Get links for txt versions of files\n",
    "            for k in range(len(html_list)):\n",
    "                txt_doc = html_list[k].replace(\"-index.html\",\".txt\")\n",
    "                doc_name = txt_doc.split(\"/\")[-1]\n",
    "                doc_list.append(txt_doc)\n",
    "                doc_name_list.append(doc_name)\n",
    "                # Create dataframe of CIK, doc name, and txt link\n",
    "            df = pd.DataFrame(\n",
    "                {\n",
    "                \"cik\" : [cik]*len(html_list),\n",
    "                \"ticker\" : [ticker]*len(html_list),\n",
    "                \"txt_link\" : doc_list,\n",
    "                \"doc_name\": doc_name_list\n",
    "                }\n",
    "            )\n",
    "        except requests.exceptions.ConnectionError:\n",
    "                sleep(.1)\n",
    "        return df\n",
    "\n",
    "    # Extracts text and submission datetime from document link\n",
    "    def extract_text(link):\n",
    "        try:\n",
    "            r = requests.get(link)\n",
    "            #Parse 8-K document\n",
    "            filing = BeautifulSoup(r.content,\"html5lib\",from_encoding=\"ascii\")\n",
    "            #Extract datetime\n",
    "            try:\n",
    "                submission_dt = filing.find(\"acceptance-datetime\").string[:14]\n",
    "            except AttributeError:\n",
    "                    # Flag docs with missing data as May 1 2018 10AM\n",
    "                submission_dt = \"20180501100000\"\n",
    "            \n",
    "            submission_dt = datetime.datetime.strptime(submission_dt,\"%Y%m%d%H%M%S\")\n",
    "            #Extract HTML sections\n",
    "            for section in filing.findAll(\"html\"):\n",
    "                try:\n",
    "                    #Remove tables\n",
    "                    for table in section(\"table\"):\n",
    "                        table.decompose()\n",
    "                    #Convert to unicode\n",
    "                    section = unicodedata.normalize(\"NFKD\",section.text)\n",
    "                    section = section.replace(\"\\t\",\" \").replace(\"\\n\",\" \").replace(\"/s\",\" \").replace(\"\\'\",\"'\")            \n",
    "                except AttributeError:\n",
    "                    section = str(section.encode('utf-8'))\n",
    "            filing = \"\".join((section))\n",
    "        except requests.exceptions.ConnectionError:\n",
    "                sleep(10)\n",
    "        sleep(.1)\n",
    "\n",
    "        return filing, submission_dt\n",
    "\n",
    "    def extract_item_no(document):\n",
    "        pattern = re.compile(\"Item+ +\\d+[\\:,\\.]+\\d+\\d\")\n",
    "        item_list = re.findall(pattern,document)\n",
    "        return item_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns Dataframe of document links for a given CIK\n",
    "idx = pd.Index\n",
    "class FinDataExtractor:\n",
    "    def __init__(self):\n",
    "        # S&P 500 index data downloaded from Yahoo Finance GSPC\n",
    "        self.gspc_df = pd.read_csv(\"Data/Indexes/gspc.csv\",parse_dates=['Date'],index_col=\"Date\")\n",
    "        # Get VIX index data downloaded from Yahoo Finance\n",
    "        self.vix_df = pd.read_csv(\"Data/Indexes/vix.csv\",parse_dates=['Date'],index_col=\"Date\")\n",
    "        nyse = mcal.get_calendar('NYSE')\n",
    "        self.nyse_holidays = nyse.holidays().holidays\n",
    "        self.all_tickers_data = pd.read_pickle(\"Pickles/all_tickers_data.pkl\")\n",
    "        \n",
    "#Takes datetime object and ticker string, returns price (opening or closing)\n",
    "    def get_historical_movements(self,row,period):\n",
    "        ticker,release_date = row[0],row[1]\n",
    "\n",
    "       #1 Week\n",
    "        if period == \"week\":\n",
    "            e_start = release_date + datetime.timedelta(weeks=-1)\n",
    "            b_start = e_start\n",
    "\n",
    "            e_end = release_date + dateutil.relativedelta.relativedelta(days=-1)\n",
    "            b_end = e_end\n",
    "\n",
    "         #1 Month    \n",
    "        elif period == \"month\":\n",
    "            e_start = release_date + dateutil.relativedelta.relativedelta(months=-1)\n",
    "            b_start = e_start + dateutil.relativedelta.relativedelta(days=-5)\n",
    "\n",
    "            e_end = release_date + dateutil.relativedelta.relativedelta(days=-1)\n",
    "            b_end = release_date + dateutil.relativedelta.relativedelta(days=-6)\n",
    "\n",
    "        #1 Quarter\n",
    "        elif period == \"quarter\":\n",
    "            e_start = release_date + dateutil.relativedelta.relativedelta(months=-3)\n",
    "            b_start = e_start + dateutil.relativedelta.relativedelta(days=-10)\n",
    "\n",
    "            e_end = release_date + dateutil.relativedelta.relativedelta(days=-1)\n",
    "            b_end = release_date + dateutil.relativedelta.relativedelta(days=-11)\n",
    "\n",
    "        #1 Year\n",
    "        elif period == \"year\":\n",
    "            e_start = release_date + dateutil.relativedelta.relativedelta(years=-1)\n",
    "            b_start = e_start + dateutil.relativedelta.relativedelta(days=-20)\n",
    "\n",
    "            e_end = release_date + dateutil.relativedelta.relativedelta(days=-1)\n",
    "            b_end = release_date + dateutil.relativedelta.relativedelta(days=-21)\n",
    "        else:\n",
    "            raise KeyError\n",
    "\n",
    "        e_start = self.weekday_check(e_start)\n",
    "        b_start = self.weekday_check(b_start)\n",
    "        e_end = self.weekday_check(e_end)\n",
    "        b_end = self.weekday_check(b_end)\n",
    "\n",
    "        start_price = self.get_av_data(ticker=ticker,start_date = b_start, end_date = e_start)\n",
    "        end_price = self.get_av_data(ticker=ticker,start_date = b_end, end_date = e_end)\n",
    "        stock_change = self.calculate_pct_change(end_price,start_price)\n",
    "\n",
    "        start_index = self.get_index_price(start_date = b_start, end_date = e_start)\n",
    "        end_index = self.get_index_price(start_date = e_start, end_date = e_end)\n",
    "        index_change =  self.calculate_pct_change(end_index,start_index)\n",
    "\n",
    "        normalized = stock_change - index_change\n",
    "        return normalized\n",
    "\n",
    "    def get_av_data(self,ticker,start_date,end_date,market_open=False):\n",
    "        start_date = start_date.date()\n",
    "        end_date = end_date.date()\n",
    "\n",
    "        try:\n",
    "            if market_open == False:\n",
    "                price = self.all_tickers_data.xs(ticker,0).loc[end_date:start_date,\"adjusted_close\"].mean()\n",
    "            else:\n",
    "                price = self.all_tickers_data.xs(ticker,0).loc[end_date:start_date,\"open\"].mean()\n",
    "        except (KeyError,IndexError):\n",
    "            price = np.nan\n",
    "        return price\n",
    "\n",
    "    # Takes ticker, 8K release date, checks time of release and then calculate before and after price change\n",
    "    def get_change(self,row):\n",
    "        release_date = row['release_date']\n",
    "        ticker = row['ticker']\n",
    "        market_close = release_date.replace(hour=16,minute=0,second=0)\n",
    "        market_open = release_date.replace(hour=9,minute=30,second=0)\n",
    "\n",
    "    # If report is released after market hours, take change of start date close and release date open\n",
    "        if release_date > market_close:\n",
    "            start_date = release_date\n",
    "            end_date = release_date + datetime.timedelta(days=1)\n",
    "            end_date = self.weekday_check(end_date)\n",
    "\n",
    "            price_before_release = self.get_av_data(ticker,start_date,start_date,market_open=False)\n",
    "            price_after_release = self.get_av_data(ticker,end_date,end_date,market_open=True)\n",
    "\n",
    "            index_before_release = self.get_index_price(start_date,start_date,market_open=False)\n",
    "            index_after_release = self.get_index_price(end_date,end_date,market_open=True)\n",
    "\n",
    "            try:\n",
    "                vix = self.vix_df.loc[self.vix_df.index == np.datetime64(start_date.date()),\"Adj Close\"][0].item()\n",
    "            except IndexError:\n",
    "                vix = np.nan\n",
    "\n",
    "        # If report is released before market hours, take change of start date's close and release date's open\n",
    "        elif release_date < market_open:\n",
    "            start_date = release_date + datetime.timedelta(days=-1)\n",
    "            start_date = self.weekday_check(start_date)\n",
    "            end_date = release_date\n",
    "\n",
    "            price_before_release = self.get_av_data(ticker,start_date,start_date,market_open=False)\n",
    "            price_after_release = self.get_av_data(ticker,end_date,end_date,market_open=True) \n",
    "\n",
    "            index_before_release = self.get_index_price(start_date,start_date,market_open=False)\n",
    "            index_after_release = self.get_index_price(end_date,end_date,market_open=True)\n",
    "            try:\n",
    "                vix = self.vix_df.loc[self.vix_df.index == np.datetime64(start_date.date()),\"Adj Close\"][0].item()\n",
    "            except IndexError:\n",
    "                vix = np.nan\n",
    "        # If report is released during market hours, use market close\n",
    "        else:\n",
    "            start_date = release_date\n",
    "            end_date = release_date\n",
    "            price_before_release = self.get_av_data(ticker,start_date,start_date,market_open=True)\n",
    "            price_after_release = self.get_av_data(ticker,end_date,end_date,market_open=False)\n",
    "\n",
    "            index_before_release = self.get_index_price(start_date,start_date,market_open=True)\n",
    "            index_after_release = self.get_index_price(end_date,end_date,market_open=False)\n",
    "            \n",
    "            try:\n",
    "                vix = self.vix_df.loc[self.vix_df.index == np.datetime64(start_date.date()),\"Open\"][0].item()\n",
    "            except IndexError:\n",
    "                vix = np.nan\n",
    "                \n",
    "        price_pct_change = self.calculate_pct_change(price_after_release,price_before_release)\n",
    "        index_pct_change = self.calculate_pct_change(index_after_release,index_before_release)\n",
    "        normalized_change = price_pct_change - index_pct_change\n",
    "\n",
    "        return normalized_change, vix\n",
    "\n",
    "    def get_index_price(self,start_date,end_date,market_open=False):\n",
    "        try:\n",
    "            if market_open == True:\n",
    "                price = self.gspc_df.loc[(self.gspc_df.index >= np.datetime64(start_date.date())) & \n",
    "                                 (self.gspc_df.index <= np.datetime64(end_date)),\"Open\"].mean()\n",
    "            else:\n",
    "                price = self.gspc_df.loc[(self.gspc_df.index >= np.datetime64(start_date.date())) & \n",
    "                                 (self.gspc_df.index <= np.datetime64(end_date)),\"Adj Close\"].mean()\n",
    "        except IndexError:\n",
    "                price = np.nan\n",
    "        return price\n",
    "\n",
    "    def calculate_pct_change(self,end_value,start_value):\n",
    "        pct_change = (end_value - start_value) / start_value\n",
    "        pct_change = round(pct_change,4) * 100\n",
    "        return pct_change\n",
    "\n",
    "    def weekday_check(self,date):  \n",
    "        while date.isoweekday() > 5 or date.date() in self.nyse_holidays:\n",
    "            date = date + datetime.timedelta(days=-1)\n",
    "        return date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get S&P 500 Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Security</th>\n",
       "      <th>SEC filings</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub-Industry</th>\n",
       "      <th>Headquarters Location</th>\n",
       "      <th>Date first added</th>\n",
       "      <th>CIK</th>\n",
       "      <th>Founded</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Symbol</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MMM</th>\n",
       "      <td>3M Company</td>\n",
       "      <td>reports</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrial Conglomerates</td>\n",
       "      <td>St. Paul, Minnesota</td>\n",
       "      <td>1976-08-09</td>\n",
       "      <td>66740</td>\n",
       "      <td>1902</td>\n",
       "      <td>Industrials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABT</th>\n",
       "      <td>Abbott Laboratories</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>1964-03-31</td>\n",
       "      <td>1800</td>\n",
       "      <td>1888</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABBV</th>\n",
       "      <td>AbbVie Inc.</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>North Chicago, Illinois</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1551152</td>\n",
       "      <td>2013 (1888)</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ABMD</th>\n",
       "      <td>ABIOMED Inc</td>\n",
       "      <td>reports</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care Equipment</td>\n",
       "      <td>Danvers, Massachusetts</td>\n",
       "      <td>2018-05-31</td>\n",
       "      <td>815094</td>\n",
       "      <td>1981</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACN</th>\n",
       "      <td>Accenture plc</td>\n",
       "      <td>reports</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>IT Consulting &amp; Other Services</td>\n",
       "      <td>Dublin, Ireland</td>\n",
       "      <td>2011-07-06</td>\n",
       "      <td>1467373</td>\n",
       "      <td>1989</td>\n",
       "      <td>Information Technology</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Security SEC filings             GICS Sector  \\\n",
       "Symbol                                                            \n",
       "MMM              3M Company     reports             Industrials   \n",
       "ABT     Abbott Laboratories     reports             Health Care   \n",
       "ABBV            AbbVie Inc.     reports             Health Care   \n",
       "ABMD            ABIOMED Inc     reports             Health Care   \n",
       "ACN           Accenture plc     reports  Information Technology   \n",
       "\n",
       "                     GICS Sub-Industry    Headquarters Location  \\\n",
       "Symbol                                                            \n",
       "MMM           Industrial Conglomerates      St. Paul, Minnesota   \n",
       "ABT              Health Care Equipment  North Chicago, Illinois   \n",
       "ABBV                   Pharmaceuticals  North Chicago, Illinois   \n",
       "ABMD             Health Care Equipment   Danvers, Massachusetts   \n",
       "ACN     IT Consulting & Other Services          Dublin, Ireland   \n",
       "\n",
       "       Date first added      CIK      Founded       GICS Sub Industry  \n",
       "Symbol                                                                 \n",
       "MMM          1976-08-09    66740         1902             Industrials  \n",
       "ABT          1964-03-31     1800         1888             Health Care  \n",
       "ABBV         2012-12-31  1551152  2013 (1888)             Health Care  \n",
       "ABMD         2018-05-31   815094         1981             Health Care  \n",
       "ACN          2011-07-06  1467373         1989  Information Technology  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get table of the S&P 500 tickers, CIK, and industry from Wikipedia\n",
    "wiki_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "cik_df = pd.read_html(wiki_url,header=0,index_col=0)[0]\n",
    "cik_df['GICS Sector'] = cik_df['GICS Sector'].astype(\"category\")\n",
    "cik_df['GICS Sub Industry'] = cik_df['GICS Sector'].astype(\"category\")\n",
    "cik_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Get List of 8K links from SEC Edgar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sec_ext = SEC_Extractor\n",
    "no_parts = 2\n",
    "part_no = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 505/505 [03:08<00:00,  2.68it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cik</th>\n",
       "      <th>txt_link</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/109087...</td>\n",
       "      <td>0001564590-18-006570.txt</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/109087...</td>\n",
       "      <td>0001090872-18-000002.txt</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/109087...</td>\n",
       "      <td>0001564590-18-000605.txt</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/109087...</td>\n",
       "      <td>0001090872-17-000015.txt</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/109087...</td>\n",
       "      <td>0001090872-17-000011.txt</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker        cik                                           txt_link  \\\n",
       "0      A  1090872.0  https://www.sec.gov/Archives/edgar/data/109087...   \n",
       "1      A  1090872.0  https://www.sec.gov/Archives/edgar/data/109087...   \n",
       "2      A  1090872.0  https://www.sec.gov/Archives/edgar/data/109087...   \n",
       "3      A  1090872.0  https://www.sec.gov/Archives/edgar/data/109087...   \n",
       "4      A  1090872.0  https://www.sec.gov/Archives/edgar/data/109087...   \n",
       "\n",
       "                   doc_name  GICS Sector GICS Sub Industry  \n",
       "0  0001564590-18-006570.txt  Health Care       Health Care  \n",
       "1  0001090872-18-000002.txt  Health Care       Health Care  \n",
       "2  0001564590-18-000605.txt  Health Care       Health Care  \n",
       "3  0001090872-17-000015.txt  Health Care       Health Care  \n",
       "4  0001090872-17-000011.txt  Health Care       Health Care  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = []\n",
    "company_list = cik_df['CIK'].to_dict()\n",
    "for (ticker,cik) in tqdm(company_list.items()):\n",
    "    df_list.append(sec_ext.get_doc_links(cik,ticker))\n",
    "doc_links_df = pd.concat(df_list,axis=0)\n",
    "doc_links_df = doc_links_df.set_index(\"ticker\").join(cik_df['GICS Sector']).join(cik_df['GICS Sub Industry']).reset_index().rename(columns={\"index\":\"ticker\"})\n",
    "doc_links_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_links_df.to_pickle(\"Pickles/doc_links_df.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Download 8Ks & Stock Movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split data into how many parts?3\n",
      "Which part is this?2\n",
      "Number of rows to process at once (10 to 50 recommended)50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:45, 45.69s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cik</th>\n",
       "      <th>txt_link</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>text</th>\n",
       "      <th>release_date</th>\n",
       "      <th>items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6424</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>746515.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/746515...</td>\n",
       "      <td>0000746515-15-000024.txt</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>0000746515-15-000024.txt : 20150518 0000746515...</td>\n",
       "      <td>2015-05-18 16:09:17</td>\n",
       "      <td>[Item 7.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6425</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>746515.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/746515...</td>\n",
       "      <td>0000746515-15-000023.txt</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>0000746515-15-000023.txt : 20150518 0000746515...</td>\n",
       "      <td>2015-05-18 16:08:02</td>\n",
       "      <td>[Item 7.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6426</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>746515.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/746515...</td>\n",
       "      <td>0000746515-15-000018.txt</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>0000746515-15-000018.txt : 20150507 0000746515...</td>\n",
       "      <td>2015-05-07 16:54:13</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6427</th>\n",
       "      <td>EXPD</td>\n",
       "      <td>746515.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/746515...</td>\n",
       "      <td>0000746515-15-000014.txt</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>0000746515-15-000014.txt : 20150506 0000746515...</td>\n",
       "      <td>2015-05-06 16:20:03</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6428</th>\n",
       "      <td>EXPE</td>\n",
       "      <td>1324424.0</td>\n",
       "      <td>https://www.sec.gov/Archives/edgar/data/132442...</td>\n",
       "      <td>0001324424-18-000013.txt</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>Consumer Discretionary</td>\n",
       "      <td>0001324424-18-000013.txt : 20180327 0001324424...</td>\n",
       "      <td>2018-03-27 14:42:14</td>\n",
       "      <td>[Item 5.03, Item 7.01, Item 7.01, Item 9.01]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ticker        cik                                           txt_link  \\\n",
       "6424   EXPD   746515.0  https://www.sec.gov/Archives/edgar/data/746515...   \n",
       "6425   EXPD   746515.0  https://www.sec.gov/Archives/edgar/data/746515...   \n",
       "6426   EXPD   746515.0  https://www.sec.gov/Archives/edgar/data/746515...   \n",
       "6427   EXPD   746515.0  https://www.sec.gov/Archives/edgar/data/746515...   \n",
       "6428   EXPE  1324424.0  https://www.sec.gov/Archives/edgar/data/132442...   \n",
       "\n",
       "                      doc_name             GICS Sector  \\\n",
       "6424  0000746515-15-000024.txt             Industrials   \n",
       "6425  0000746515-15-000023.txt             Industrials   \n",
       "6426  0000746515-15-000018.txt             Industrials   \n",
       "6427  0000746515-15-000014.txt             Industrials   \n",
       "6428  0001324424-18-000013.txt  Consumer Discretionary   \n",
       "\n",
       "           GICS Sub Industry  \\\n",
       "6424             Industrials   \n",
       "6425             Industrials   \n",
       "6426             Industrials   \n",
       "6427             Industrials   \n",
       "6428  Consumer Discretionary   \n",
       "\n",
       "                                                   text        release_date  \\\n",
       "6424  0000746515-15-000024.txt : 20150518 0000746515... 2015-05-18 16:09:17   \n",
       "6425  0000746515-15-000023.txt : 20150518 0000746515... 2015-05-18 16:08:02   \n",
       "6426  0000746515-15-000018.txt : 20150507 0000746515... 2015-05-07 16:54:13   \n",
       "6427  0000746515-15-000014.txt : 20150506 0000746515... 2015-05-06 16:20:03   \n",
       "6428  0001324424-18-000013.txt : 20180327 0001324424... 2018-03-27 14:42:14   \n",
       "\n",
       "                                             items  \n",
       "6424                                   [Item 7.01]  \n",
       "6425                                   [Item 7.01]  \n",
       "6426             [Item 2.02, Item 2.02, Item 9.01]  \n",
       "6427             [Item 2.02, Item 2.02, Item 9.01]  \n",
       "6428  [Item 5.03, Item 7.01, Item 7.01, Item 9.01]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while part_no > no_parts:\n",
    "    no_parts = int(input(\"Split data into how many parts?\"))\n",
    "    part_no = int(input(\"Which part is this?\"))\n",
    "    \n",
    "chunksize = int(input(\"Number of rows to process at once (10 to 50 recommended)\"))\n",
    "\n",
    "#Load pickle\n",
    "crawled_df = np.array_split(pd.read_pickle(\"Pickles/doc_links_df.pkl\"),no_parts)[part_no-1][:10]\n",
    "crawled_len = len(crawled_df['txt_link'])\n",
    "chunks = math.ceil(crawled_len/chunksize)\n",
    "\n",
    "df_list = []\n",
    "for i, df in tqdm(enumerate(np.array_split(crawled_df,chunks))):\n",
    "    df['text'], df['release_date'] = zip(*df['txt_link'].apply(sec_ext.extract_text))\n",
    "    df['items'] = df['text'].map(sec_ext.extract_item_no)\n",
    "    if not os.path.isfile(\"Data/texts_example{}.csv.gzip\".format(part_no)): #If no file exists, create one with header\n",
    "        df.to_csv(\"Data/texts_example{}.csv.gzip\".format(part_no),chunksize=chunksize,compression=\"gzip\")\n",
    "    else: # else it exists so append without writing the header\n",
    "        df.to_csv(\"Data/texts_example{}.csv.gzip\".format(part_no),mode=\"a\",header=False,compression=\"gzip\",chunksize=chunksize)       \n",
    "    df_list.append(df)\n",
    "    del df\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        gc.collect()\n",
    "df = pd.concat(df_list)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cik_dict = cik_df['CIK'].to_dict()\n",
    "cik_dict = {v: k for k, v in cik_dict.items()}\n",
    "df['ticker'] = df['cik'].map(cik_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1_gen = pd.read_csv(\"Data/texts1.csv.gzip\",compression=\"gzip\",parse_dates=['release_date'],chunksize=1000,index_col=[0])\n",
    "#df2_gen = pd.read_csv(\"Data/texts2.csv.gzip\",compression=\"gzip\",parse_dates=['release_date'],chunksize=1000)\n",
    "df1 = pd.concat([df for df in df1_gen])\n",
    "#df2 = pd.concat([df for df in df2_gen])\n",
    "#df2 = pd.read_csv(\"Data/texts2.csv\",parse_dates=['release_date'],encoding=\"utf_8\",index_col=[0])\n",
    "gc.collect()\n",
    "#df = pd.concat([df1,df2],axis=0)\n",
    "df=pd.concat([df1], axis=0)\n",
    "gc.collect()\n",
    "df['items'] = df['items'].map(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ticker</th>\n",
       "      <th>cik</th>\n",
       "      <th>doc_name</th>\n",
       "      <th>txt_link</th>\n",
       "      <th>GICS Sector</th>\n",
       "      <th>GICS Sub Industry</th>\n",
       "      <th>text</th>\n",
       "      <th>release_date</th>\n",
       "      <th>items</th>\n",
       "      <th>price_change</th>\n",
       "      <th>vix</th>\n",
       "      <th>rm_week</th>\n",
       "      <th>rm_month</th>\n",
       "      <th>rm_qtr</th>\n",
       "      <th>rm_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001564590-18-006570.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001564590-18-006570.txt : 20180322 0001564590...</td>\n",
       "      <td>2018-03-22 16:22:07</td>\n",
       "      <td>[Item 5.07]</td>\n",
       "      <td>0.05</td>\n",
       "      <td>23.34</td>\n",
       "      <td>-0.41</td>\n",
       "      <td>-3.07</td>\n",
       "      <td>1.78</td>\n",
       "      <td>26.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001090872-18-000002.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001090872-18-000002.txt : 20180214 0001090872...</td>\n",
       "      <td>2018-02-14 16:27:02</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "      <td>6.97</td>\n",
       "      <td>19.26</td>\n",
       "      <td>1.95</td>\n",
       "      <td>-5.76</td>\n",
       "      <td>-3.62</td>\n",
       "      <td>35.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001564590-18-000605.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001564590-18-000605.txt : 20180118 0001564590...</td>\n",
       "      <td>2018-01-18 16:09:52</td>\n",
       "      <td>[Item 5.02, Item 9.01]</td>\n",
       "      <td>0.24</td>\n",
       "      <td>12.22</td>\n",
       "      <td>1.22</td>\n",
       "      <td>4.93</td>\n",
       "      <td>3.15</td>\n",
       "      <td>38.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001090872-17-000015.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001090872-17-000015.txt : 20171120 0001090872...</td>\n",
       "      <td>2017-11-20 16:09:02</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>10.65</td>\n",
       "      <td>2.71</td>\n",
       "      <td>1.31</td>\n",
       "      <td>9.54</td>\n",
       "      <td>39.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>1090872</td>\n",
       "      <td>0001090872-17-000011.txt</td>\n",
       "      <td>http://www.sec.gov/Archives/edgar/data/1090872...</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>Health Care</td>\n",
       "      <td>0001090872-17-000011.txt : 20170815 0001090872...</td>\n",
       "      <td>2017-08-15 16:12:29</td>\n",
       "      <td>[Item 2.02, Item 2.02, Item 9.01]</td>\n",
       "      <td>4.50</td>\n",
       "      <td>12.04</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>-3.34</td>\n",
       "      <td>4.39</td>\n",
       "      <td>21.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ticker      cik                  doc_name  \\\n",
       "0      A  1090872  0001564590-18-006570.txt   \n",
       "1      A  1090872  0001090872-18-000002.txt   \n",
       "2      A  1090872  0001564590-18-000605.txt   \n",
       "3      A  1090872  0001090872-17-000015.txt   \n",
       "4      A  1090872  0001090872-17-000011.txt   \n",
       "\n",
       "                                            txt_link  GICS Sector  \\\n",
       "0  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "1  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "2  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "3  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "4  http://www.sec.gov/Archives/edgar/data/1090872...  Health Care   \n",
       "\n",
       "  GICS Sub Industry                                               text  \\\n",
       "0       Health Care  0001564590-18-006570.txt : 20180322 0001564590...   \n",
       "1       Health Care  0001090872-18-000002.txt : 20180214 0001090872...   \n",
       "2       Health Care  0001564590-18-000605.txt : 20180118 0001564590...   \n",
       "3       Health Care  0001090872-17-000015.txt : 20171120 0001090872...   \n",
       "4       Health Care  0001090872-17-000011.txt : 20170815 0001090872...   \n",
       "\n",
       "         release_date                              items  price_change    vix  \\\n",
       "0 2018-03-22 16:22:07                        [Item 5.07]          0.05  23.34   \n",
       "1 2018-02-14 16:27:02  [Item 2.02, Item 2.02, Item 9.01]          6.97  19.26   \n",
       "2 2018-01-18 16:09:52             [Item 5.02, Item 9.01]          0.24  12.22   \n",
       "3 2017-11-20 16:09:02  [Item 2.02, Item 2.02, Item 9.01]         -0.14  10.65   \n",
       "4 2017-08-15 16:12:29  [Item 2.02, Item 2.02, Item 9.01]          4.50  12.04   \n",
       "\n",
       "   rm_week  rm_month  rm_qtr  rm_year  \n",
       "0    -0.41     -3.07    1.78    26.37  \n",
       "1     1.95     -5.76   -3.62    35.35  \n",
       "2     1.22      4.93    3.15    38.90  \n",
       "3     2.71      1.31    9.54    39.85  \n",
       "4    -0.21     -3.34    4.39    21.40  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rsdata/myenv/lib/python3.7/site-packages/ipykernel_launcher.py:2: FutureWarning: The pandas.datetime class is deprecated and will be removed from pandas in a future version. Import from datetime module instead.\n",
      "  \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot insert ticker, already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-b25d0a909d62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"doc_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mreset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill)\u001b[0m\n\u001b[1;32m   4853\u001b[0m                 \u001b[0;31m# to ndarray and maybe infer different dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4854\u001b[0m                 \u001b[0mlevel_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_maybe_casted_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4855\u001b[0;31m                 \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4857\u001b[0m         \u001b[0mnew_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   3622\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_valid_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3623\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sanitize_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3624\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_duplicates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_duplicates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3626\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36minsert\u001b[0;34m(self, loc, item, value, allow_duplicates)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicates\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0;31m# Should this be a different kind of error??\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"cannot insert {item}, already exists\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot insert ticker, already exists"
     ]
    }
   ],
   "source": [
    "# Find rows flagged where no date was found\n",
    "df = df.loc[~(df['release_date'] >= pd.datetime(year=2018,month=5,day=1))]\n",
    "df = df.drop_duplicates(subset=\"doc_name\")\n",
    "df.index.names = ['ticker']\n",
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'str' and 'datetime.date'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2894\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2895\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: datetime.date(2018, 3, 22)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   5082\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5083\u001b[0;31m             \u001b[0mslc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5084\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2897\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: datetime.date(2018, 3, 22)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-8ab6d211b622>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m## Load pickle of ticker, date, and doc number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price_change'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'vix'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'release_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_change\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rm_week'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'release_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_historical_movements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"week\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rm_month'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ticker'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'release_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_historical_movements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mperiod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"month\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7546\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7547\u001b[0m         )\n\u001b[0;32m-> 7548\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7550\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"DataFrame\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                     \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                         \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-17b66e960adc>\u001b[0m in \u001b[0;36mget_change\u001b[0;34m(self, row)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mend_date\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweekday_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mprice_before_release\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_av_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarket_open\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mprice_after_release\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_av_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmarket_open\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-17b66e960adc>\u001b[0m in \u001b[0;36mget_av_data\u001b[0;34m(self, ticker, start_date, end_date, market_open)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmarket_open\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m                 \u001b[0mprice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_tickers_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"adjusted_close\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m                 \u001b[0mprice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_tickers_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"open\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    871\u001b[0m                     \u001b[0;31m# AttributeError for IntervalTree get_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    874\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# we by definition only have the 0th axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_tuple\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtup\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_lowerdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_lowerdim\u001b[0;34m(self, tup)\u001b[0m\n\u001b[1;32m    808\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0msection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m                 \u001b[0;31m# This is an elided recursive call to iloc/loc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"not applicable\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    877\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1087\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_slice_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_bool_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getbool_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_slice_axis\u001b[0;34m(self, slice_obj, axis)\u001b[0m\n\u001b[1;32m   1121\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         indexer = labels.slice_indexer(\n\u001b[0;32m-> 1123\u001b[0;31m             \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"loc\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m         )\n\u001b[1;32m   1125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_indexer\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   4964\u001b[0m         \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4965\u001b[0m         \"\"\"\n\u001b[0;32m-> 4966\u001b[0;31m         \u001b[0mstart_slice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_locs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4967\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4968\u001b[0m         \u001b[0;31m# return a slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mslice_locs\u001b[0;34m(self, start, end, step, kind)\u001b[0m\n\u001b[1;32m   5165\u001b[0m         \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5167\u001b[0;31m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice_bound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5168\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstart_slice\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5169\u001b[0m             \u001b[0mstart_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_slice_bound\u001b[0;34m(self, label, side, kind)\u001b[0m\n\u001b[1;32m   5084\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5085\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5086\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_searchsorted_monotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5087\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5088\u001b[0m                 \u001b[0;31m# raise the original KeyError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_searchsorted_monotonic\u001b[0;34m(self, label, side)\u001b[0m\n\u001b[1;32m   5035\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_searchsorted_monotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_monotonic_increasing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5037\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5038\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_monotonic_decreasing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5039\u001b[0m             \u001b[0;31m# np.searchsorted expects ascending sort order, have to reverse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/base.py\u001b[0m in \u001b[0;36msearchsorted\u001b[0;34m(self, value, side, sorter)\u001b[0m\n\u001b[1;32m   1499\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"searchsorted\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdrop_duplicates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"first\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36msearchsorted\u001b[0;34m(arr, value, side, sorter)\u001b[0m\n\u001b[1;32m   1860\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime64\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mside\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mside\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msorter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msorter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '<' not supported between instances of 'str' and 'datetime.date'"
     ]
    }
   ],
   "source": [
    "#from FinDataExtractor import FinDataExtractor\n",
    "fin_data = FinDataExtractor()\n",
    "## Load pickle of ticker, date, and doc number\n",
    "\n",
    "df['price_change'],df['vix'] = zip(*df[['ticker','release_date']].apply(fin_data.get_change,axis=1))\n",
    "df['rm_week'] = df[['ticker','release_date']].apply(fin_data.get_historical_movements,period=\"week\",axis=1)\n",
    "df['rm_month'] = df[['ticker','release_date']].apply(fin_data.get_historical_movements,period=\"month\",axis=1)\n",
    "df['rm_qtr'] = df[['ticker','release_date']].apply(fin_data.get_historical_movements,period=\"quarter\",axis=1)\n",
    "df['rm_year'] = df[['ticker','release_date']].apply(fin_data.get_historical_movements,period=\"year\",axis=1)\n",
    "df[\"signal\"] = df['price_change'].map(lambda x: \"stay\" if -1<x<1 else (\"up\" if x>1 else \"down\"))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 362.46it/s]\n"
     ]
    }
   ],
   "source": [
    "chunks = 20\n",
    "for i, df_part in tqdm(enumerate(np.array_split(df,chunks))):\n",
    "    if not os.path.isfile(\"Data/texts_and_fin.csv\"): #If no file exists, create one with header\n",
    "        df_part.to_csv(\"Data/texts_and_fin.csv\")\n",
    "    else: # else it exists so append without writing the header\n",
    "        df_part.to_csv(\"Data/texts_and_fin.csv\",mode=\"a\",header=False,)       \n",
    "    del df_part\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
